---
sidebar_position: 1
---

# 2023-04 每日读论文

每天强迫自己看 30 分钟 AI 相关论文，不追求把新的都看完，重点是保持关注。为了能让我坚持下来，计划每天将看过的论文链接和我的一些看法发出来。也希望能获得大家的反馈，比如指出我的错误理解等。Learn in public 😄

不保证能持续更新，且时间有限，我一般只会细看结论，粗看研究过程，遇到需要精读的会先收藏，后续再细看。所以分享的质量会不尽如人意。

请各位谨慎关注 🤣

我主要使用的工具是：

- BriefGPT.xyz（推荐各位使用）
- Zotero（用于保存论文和做笔记）
- 闹钟（是个物理闹钟，打开第一个工具，然后设置好 30 分钟提醒）

2023-04-24：

- [GPT4Tools：通过 Self-instruction 来教授 LLM 使用工具](https://gpt4tools.github.io/)（暂时还没在 arxiv 上）：在众多微软和谷歌的论文中，终于看到了篇腾讯 AI Lab 的论文。简单说来，这个 Tool 可以让用户使用文字对话的方式对图形进行诸如换背景、去除照片中的某个主体等交互。里面我觉得值得关注的是它可以根据需要替换 LLMs 模型，以及使用 LoRA 进行微调。
- [利用大型语言模型协助医生改善临床试验的患者预筛选](https://arxiv.org/pdf/2304.07396)：论文中说他们是第一个引入 LLMs 来帮助医生对临床实验资格进行筛查的团队。医生使用 LLMs 工具后，能简化 90% 的检查。
- [Low-code LLM: Visual Programming over LLMs](https://arxiv.org/pdf/2304.08103.pdf)：本文介绍了一种新的人和 LLMs 交互的框架——Low-code LLM。通过与图形用户界面进行可视化交互，用户可以将他们的想法融入工作流程中，而无需编写琐碎的提示。我觉得很适合最近的 Auto 或者 Agent GPT。
- [使用人工智能编程是怎样的体验？](https://arxiv.org/pdf/2208.06213.pdf)：因为我最近一直在用 Github Copilot 所以对文中的内容没啥感觉。里面对我有价值的部分是知道微软有个叫 [GridBook](https://www.microsoft.com/en-us/research/project/gridbook/) 的 Demo，允许用户使用自然语言编写 Excel 的公式。

2023-04-25：

- [Scaling Transformer to 1M tokens and beyond with RMT](https://arxiv.org/pdf/2304.11062.pdf)：这篇论文，在 Twitter 上挺火的。大语言模型目前最大的问题是 token 限制，这篇论文提到，可以运用循环记忆技术扩展 BERT 在自然语言处理中的作用，在保持高精度的同时，将模型的有效上下文长度最高提高到两百万个 tokens。简单换算应该有将近 150 万个英文单词。细看了下，大规模工程运用还需要等一等。目前看起来资源消耗还挺大的。
- [Renate: A Library for Real-World Continual Learning](https://arxiv.org/pdf/2304.12067.pdf)：持续学习（Continual Learning）是指将机器学习模型应用于动态数据流的能力，并且在新数据到来时自适应地更新模型，而不需要从头开始重新训练。与传统的机器学习方法不同，持续学习需要在模型训练期间考虑到数据流的非稳定性和不确定性，以适应不同场景下可能出现的各种变化。本篇论文提到的 Renate 库就是一个可在生产环境使用的的 PyTorch 持续学习库。

2023-04-26：

我觉得还是昨天的两篇（特别是第一篇）牛逼。

- [AudioGPT：了解和生成语音、音乐、声音和说话人](https://arxiv.org/pdf/2304.12995.pdf)：本文提出了一种名为 AudioGPT 的多模 AI 系统，该系统结合了基础模型来处理复杂的音频信息和解决许多理解和生成任务，以及支持口语对话的输入 / 输出接口（ASR，TTS），并通过一系列实验证明了 AudioGPT 在多轮对话中具有语音、音乐、声音和对话理解和生成任务的能力。
- [通过对多个思维链进行元推理](https://arxiv.org/pdf/2304.13007.pdf)：现代的多跳问题回答（QA）系统通常会将问题分解成一系列推理步骤，称为思维链（CoT），然后才能得出最终的答案。通常情况下，会对多个链进行抽样，并通过对最终答案进行投票机制进行聚合，但是中间步骤本身会被抛弃。虽然这样的方法可以提高性能，但是它们没有考虑到链之间的中间步骤之间的关系，并且没有为预测答案提供统一的解释。多链推理（MCR）的方法使大型语言模型在多个思维链上进行元推理，而不是聚合它们的答案。MCR 检查不同的推理链，在它们之间混合信息，并选择在生成解释和预测答案时最相关的事实。

2023-04-27：

- [Towards Explainable and Safe Conversational Agents for Mental Health: A Survey](https://arxiv.org/pdf/2304.13191.pdf)：如果你对 AI 在心理健康领域的应用感兴趣，不妨看看这篇论文。这篇论文作者基于 297 个有关心理健康的研究，对大约 80 种智能技术进行了系统调查。
- [Evaluation of GPT-3.5 and GPT-4 for supporting real-world information needs in healthcare delivery](https://arxiv.org/pdf/2304.13714.pdf)：本文介绍了两个大型语言模型在医疗保健领域中的应用。结果表明，GPT-3.5 和 GPT-4 的回答对患者没有明显伤害或风险，但仅有少于 20% 的回答与信息咨询服务中已知的答案一致（不是很理解这个服务，我的理解应该还类似在线医疗咨询服务？），且它们的回答包含幻想参考（不过医生对这些 AI 幻想出来的回答，是否对人类构成伤害存在分歧，部分医生觉得是有害的）。不过论文，认为如果能对数据进行 fine-tuning，并使用更高级的 prompt engineering 能提升它们的实用性。
- [HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face](https://arxiv.org/pdf/2303.17580.pdf)：在这篇论文中，作者提出了一个 HuggingGPT 的系统。我的理解有点像 ChatGPT 的插件系统，用户提供文本与 LLM 交流，然后 LLM 在合适的时机，调用合适的 API。而这个系统调用的不是 API，而是 Hugging Face 上的模型，这样就能实现用 A 模型读图，B 模型生成图片。

2023-04-28：

- [Industrial Engineering with Large Language Models: A case study of ChatGPT’s performance on Oil & Gas problems](https://arxiv.org/pdf/2304.14354.pdf)：这是一份 Case Study，主要结论是 LLMs 有可能在工业工程中，特别是石油和天然气工程中有用。本文通过岩石物理学的例子，展示了 LLMs 在解决石油和天然气工程各个领域问题的潜在应用，这些领域一般包括，如全波形反演（FWI）、声学反射、水动压力脉冲反射和井下干预。
- [Multi-Party Chat: Conversational Agents in Group Settings with Humans and Models](https://arxiv.org/pdf/2304.13835.pdf)：目前很多 LLMs Chat 产品都是单聊模式，比如你让 AI 扮演某个角色，然后它就基于这个角色跟你聊。而这篇论文则是研究多角色的情况，让 AI 扮演多个角色。如果 Chat 产品能有多角色进行对话，应该会很有意思。对了这篇论文的第一作者也叫 Jimmy 🤣

